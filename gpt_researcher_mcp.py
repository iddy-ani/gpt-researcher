#!/usr/bin/env python3
'''
MCP Server: gpt-researcher
Description: Provides AI-powered research capabilities through GPT Researcher

Compatible with Intel MCP Framework
'''

import asyncio
import json
import os
import sys
from datetime import datetime
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import (
    Resource,
    Tool,
    Prompt,
    TextContent,
    ImageContent,
    EmbeddedResource,
    CallToolRequest,
    ListToolsRequest,
    ListResourcesRequest,
    ReadResourceRequest,
    ListPromptsRequest,
    GetPromptRequest
)

# Add the gpt_researcher directory to the path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import GPT Researcher
try:
    from gpt_researcher import GPTResearcher
    from gpt_researcher.config.config import Config
except ImportError as e:
    print(f"Error importing GPT Researcher: {e}", file=sys.stderr)
    sys.exit(1)

# Initialize the MCP server
server = Server("gpt-researcher")

# Report types supported by GPT Researcher
SUPPORTED_REPORT_TYPES = [
    "research_report",
    "custom_report", 
    "subtopic_report",
    "outline_report",
    "resource_report",
    "detailed_report"
]

async def conduct_research_task(arguments: dict) -> list[dict]:
    '''
    Conduct AI-powered research on a given topic
    '''
    query = arguments.get('query', '').strip()
    report_type = arguments.get('report_type', 'research_report')
    
    if not query:
        return [{
            "type": "text",
            "text": "Error: Query is required. Please provide a research topic or question."
        }]
    
    if report_type not in SUPPORTED_REPORT_TYPES:
        return [{
            "type": "text", 
            "text": f"Error: Unsupported report type '{report_type}'. Supported types: {', '.join(SUPPORTED_REPORT_TYPES)}"
        }]
    
    try:
        # Initialize GPT Researcher
        researcher = GPTResearcher(query=query, report_type=report_type)
        
        # Conduct research
        print(f"ğŸ” Starting research on: {query}", file=sys.stderr)
        research_result = await researcher.conduct_research()
        
        # Generate report
        print(f"ğŸ“ Generating {report_type} report...", file=sys.stderr)
        report = await researcher.write_report()
        
        # Format the response
        response_text = f"""# Research Report: {query}

**Report Type:** {report_type}
**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Sources Found:** {len(research_result) if research_result else 0}

---

{report}

---

*Report generated by ExpertGPT Researcher*
"""
        
        return [{
            "type": "text",
            "text": response_text
        }]
        
    except Exception as e:
        error_msg = f"Research failed: {str(e)}"
        print(f"âŒ {error_msg}", file=sys.stderr)
        return [{
            "type": "text",
            "text": f"Error: {error_msg}"
        }]

async def quick_research(arguments: dict) -> list[dict]:
    '''
    Conduct quick research with fewer sources for faster results
    '''
    query = arguments.get('query', '').strip()
    
    if not query:
        return [{
            "type": "text",
            "text": "Error: Query is required. Please provide a research topic or question."
        }]
    
    try:
        # Initialize GPT Researcher with custom settings for quick research
        researcher = GPTResearcher(query=query, report_type="research_report")
        
        # Override some config for faster results
        config = researcher.cfg
        config.max_iterations = 2  # Fewer iterations
        config.max_search_results_per_query = 3  # Fewer sources per query
        
        print(f"âš¡ Starting quick research on: {query}", file=sys.stderr)
        
        # Conduct research
        research_result = await researcher.conduct_research()
        
        # Generate report
        report = await researcher.write_report()
        
        # Format the response
        response_text = f"""# Quick Research: {query}

**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Sources:** {len(research_result) if research_result else 0}

{report}

*Quick research completed using GPT Researcher*
"""
        
        return [{
            "type": "text",
            "text": response_text
        }]
        
    except Exception as e:
        error_msg = f"Quick research failed: {str(e)}"
        print(f"âŒ {error_msg}", file=sys.stderr)
        return [{
            "type": "text",
            "text": f"Error: {error_msg}"
        }]

async def generate_subtopics(arguments: dict) -> list[dict]:
    '''
    Generate subtopics for a research topic
    '''
    query = arguments.get('query', '').strip()
    max_subtopics = arguments.get('max_subtopics', 5)
    
    if not query:
        return [{
            "type": "text",
            "text": "Error: Query is required. Please provide a research topic."
        }]
    
    try:
        # Initialize GPT Researcher
        researcher = GPTResearcher(query=query, report_type="subtopic_report")
        
        print(f"ğŸ§© Generating subtopics for: {query}", file=sys.stderr)
        
        # Conduct research to gather context
        await researcher.conduct_research()
        
        # Generate subtopics (this is part of the research process)
        # For now, we'll generate a subtopic outline report
        report = await researcher.write_report()
        
        response_text = f"""# Subtopics for: {query}

**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Max Subtopics:** {max_subtopics}

{report}

*Subtopics generated by GPT Researcher*
"""
        
        return [{
            "type": "text",
            "text": response_text
        }]
        
    except Exception as e:
        error_msg = f"Subtopic generation failed: {str(e)}"
        print(f"âŒ {error_msg}", file=sys.stderr)
        return [{
            "type": "text",
            "text": f"Error: {error_msg}"
        }]

async def check_system_status(arguments: dict) -> list[dict]:
    '''
    Check GPT Researcher system status and configuration
    '''
    try:
        # Get configuration
        config = Config()
        
        # Check environment variables
        egpt_key = "Set" if os.getenv('EGPT_API_KEY') else "Not set"
        openai_base_url = os.getenv('OPENAI_BASE_URL', 'Not set')
        
        status_text = f"""# GPT Researcher System Status

**Configuration:**
- LLM Provider: {config.smart_llm_provider}
- LLM Model: {config.smart_llm_model}
- Embedding Provider: {config.embedding_provider}
- Embedding Model: {config.embedding_model}
- Retriever: {', '.join(config.retrievers) if hasattr(config, 'retrievers') else 'Unknown'}

**Environment:**
- EGPT_API_KEY: {egpt_key}
- OPENAI_BASE_URL: {openai_base_url}

**Report Types Available:**
{chr(10).join(f"- {rt}" for rt in SUPPORTED_REPORT_TYPES)}

**Status:** âœ… System Ready
**Timestamp:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

*GPT Researcher MCP Server v1.0*
"""
        
        return [{
            "type": "text",
            "text": status_text
        }]
        
    except Exception as e:
        error_msg = f"Status check failed: {str(e)}"
        print(f"âŒ {error_msg}", file=sys.stderr)
        return [{
            "type": "text",
            "text": f"Error: {error_msg}"
        }]

# Resource readers
async def read_research_capabilities() -> str:
    '''
    Information about GPT Researcher capabilities
    '''
    return """GPT Researcher Capabilities:

GPT Researcher is an AI-powered research tool that can:

ğŸ” **Research Capabilities:**
- Conduct comprehensive research on any topic
- Generate detailed reports with citations
- Search multiple sources and synthesize information
- Support various report types and formats

ğŸ“Š **Report Types:**
- research_report: Comprehensive research with analysis
- custom_report: Tailored reports for specific needs
- subtopic_report: Break down topics into subtopics
- outline_report: Structured outlines and summaries
- resource_report: Focus on gathering resources
- detailed_report: In-depth analysis with extensive detail

ğŸ›  **Technical Features:**
- Uses Intel's internal API for LLM processing
- Azure OpenAI embeddings for semantic search
- DuckDuckGo integration for web search
- Configurable search depth and iteration limits
- Support for multiple languages and formats

ğŸ’¡ **Use Cases:**
- Academic research and analysis
- Market research and competitive analysis
- Technical documentation and reports
- Due diligence and fact-checking
- Content creation and journalism
- Strategic planning and decision support

Configuration: Hardcoded for Intel internal infrastructure
Status: """ + ("âœ… Active" if os.getenv('EGPT_API_KEY') else "âš ï¸ API Key Required")

async def read_research_examples() -> str:
    '''
    Examples of research queries and use cases
    '''
    return """GPT Researcher Examples:

ğŸ“ **Sample Research Queries:**

1. **Technology Analysis:**
   - "What are the latest developments in quantum computing?"
   - "Compare different AI model architectures for natural language processing"
   - "Analyze the security implications of edge computing"

2. **Market Research:**
   - "What are the current trends in renewable energy adoption?"
   - "Analyze the competitive landscape for electric vehicles in 2024"
   - "Research the growth potential of the cybersecurity market"

3. **Academic Research:**
   - "Summarize recent research on climate change mitigation strategies"
   - "What are the ethical implications of AI in healthcare?"
   - "Research the effectiveness of remote work on productivity"

4. **Business Intelligence:**
   - "What are the key factors driving digital transformation?"
   - "Analyze supply chain disruptions in the semiconductor industry"
   - "Research emerging fintech trends and regulations"

ğŸ¯ **Best Practices:**
- Be specific in your research queries
- Use clear, focused questions
- Consider the scope and depth needed
- Choose appropriate report types
- Allow sufficient time for comprehensive research

âš¡ **Quick vs. Comprehensive:**
- Use 'quick-research' for fast overviews
- Use 'conduct-research' for detailed analysis
- Use 'generate-subtopics' to explore topic structure

Examples generated based on GPT Researcher capabilities and Intel use cases."""

# Prompt generators
async def generate_research_plan(arguments: dict) -> dict:
    '''
    Generate a structured research plan for a topic
    '''
    topic = arguments.get('topic', 'your research topic')
    scope = arguments.get('scope', 'comprehensive')
    timeline = arguments.get('timeline', 'standard')
    
    prompt_text = f"""Create a detailed research plan for: {topic}

Research Scope: {scope}
Timeline: {timeline}

Please provide a structured research plan that includes:

1. **Research Objectives:**
   - Primary research questions
   - Key areas to investigate
   - Expected outcomes and deliverables

2. **Research Strategy:**
   - Information sources to consult
   - Search terms and keywords
   - Methodological approach

3. **Report Structure:**
   - Recommended report type
   - Section outline and organization
   - Key points to address

4. **Execution Plan:**
   - Research phases and milestones
   - Resource requirements
   - Quality assurance steps

5. **Success Criteria:**
   - How to measure research completeness
   - Quality indicators
   - Validation methods

Focus on creating an actionable plan that maximizes research efficiency and output quality for the given topic and constraints."""

    return {
        "description": "Generate a structured research plan",
        "arguments": [
            {"name": "topic", "description": "Research topic or question", "required": True},
            {"name": "scope", "description": "Research scope (focused, comprehensive, exploratory)", "required": False},
            {"name": "timeline", "description": "Timeline constraints (urgent, standard, extended)", "required": False}
        ],
        "prompt": prompt_text
    }

async def generate_analysis_framework(arguments: dict) -> dict:
    '''
    Generate an analysis framework for research findings
    '''
    topic = arguments.get('topic', 'your research topic')
    analysis_type = arguments.get('analysis_type', 'general')
    
    prompt_text = f"""Create an analysis framework for research on: {topic}

Analysis Type: {analysis_type}

Please provide a comprehensive analysis framework that includes:

1. **Analytical Dimensions:**
   - Key factors and variables to analyze
   - Relationships and dependencies
   - Critical success factors

2. **Evaluation Criteria:**
   - Quality metrics and indicators
   - Comparative benchmarks
   - Assessment methodologies

3. **Synthesis Approach:**
   - How to integrate findings
   - Pattern recognition techniques
   - Insight generation methods

4. **Validation Framework:**
   - Source credibility assessment
   - Cross-verification methods
   - Bias detection and mitigation

5. **Presentation Strategy:**
   - Key message development
   - Supporting evidence organization
   - Stakeholder-specific insights

The framework should help ensure thorough, objective, and actionable analysis of research findings on this topic."""

    return {
        "description": "Generate an analysis framework for research",
        "arguments": [
            {"name": "topic", "description": "Research topic or domain", "required": True},
            {"name": "analysis_type", "description": "Type of analysis (comparative, trend, risk, opportunity)", "required": False}
        ],
        "prompt": prompt_text
    }

# MCP Server Implementation
@server.list_tools()
async def handle_list_tools() -> list[Tool]:
    """List available tools."""
    return [
        Tool(
            name="conduct-research",
            description="Conduct comprehensive AI-powered research on any topic",
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Research topic or question"
                    },
                    "report_type": {
                        "type": "string",
                        "enum": SUPPORTED_REPORT_TYPES,
                        "default": "research_report",
                        "description": "Type of report to generate"
                    }
                },
                "required": ["query"]
            }
        ),
        Tool(
            name="quick-research",
            description="Conduct quick research with fewer sources for faster results",
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Research topic or question"
                    }
                },
                "required": ["query"]
            }
        ),
        Tool(
            name="generate-subtopics",
            description="Generate subtopics for a research area",
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Main research topic"
                    },
                    "max_subtopics": {
                        "type": "integer",
                        "minimum": 3,
                        "maximum": 10,
                        "default": 5,
                        "description": "Maximum number of subtopics to generate"
                    }
                },
                "required": ["query"]
            }
        ),
        Tool(
            name="check-status",
            description="Check GPT Researcher system status and configuration",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            }
        )
    ]

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict) -> list[dict]:
    """Handle tool calls."""
    if name == "conduct-research":
        return await conduct_research_task(arguments)
    elif name == "quick-research":
        return await quick_research(arguments)
    elif name == "generate-subtopics":
        return await generate_subtopics(arguments)
    elif name == "check-status":
        return await check_system_status(arguments)
    else:
        raise ValueError(f"Unknown tool: {name}")

@server.list_resources()
async def handle_list_resources() -> list[Resource]:
    """List available resources."""
    return [
        Resource(
            uri="research://capabilities",
            name="research-capabilities",
            description="GPT Researcher capabilities and features"
        ),
        Resource(
            uri="research://examples",
            name="research-examples",
            description="Example research queries and use cases"
        )
    ]

@server.read_resource()
async def handle_read_resource(uri: str) -> str:
    """Read resource content."""
    if uri == "research://capabilities":
        return await read_research_capabilities()
    elif uri == "research://examples":
        return await read_research_examples()
    else:
        raise ValueError(f"Unknown resource: {uri}")

@server.list_prompts()
async def handle_list_prompts() -> list[Prompt]:
    """List available prompts."""
    return [
        Prompt(
            name="research-plan",
            description="Generate a structured research plan"
        ),
        Prompt(
            name="analysis-framework",
            description="Generate an analysis framework for research"
        )
    ]

@server.get_prompt()
async def handle_get_prompt(name: str, arguments: dict) -> dict:
    """Get prompt details."""
    if name == "research-plan":
        return await generate_research_plan(arguments)
    elif name == "analysis-framework":
        return await generate_analysis_framework(arguments)
    else:
        raise ValueError(f"Unknown prompt: {name}")

async def main():
    """Main function to run the MCP server"""
    try:
        # Ensure UTF-8 encoding for stdout/stderr
        if hasattr(sys.stdout, 'reconfigure'):
            sys.stdout.reconfigure(encoding='utf-8')
            sys.stderr.reconfigure(encoding='utf-8')
        
        print("ğŸš€ Starting GPT Researcher MCP Server...", file=sys.stderr)
        
        # Check basic configuration
        config = Config()
        print(f"ğŸ“Š LLM Provider: {config.smart_llm_provider}", file=sys.stderr)
        print(f"ğŸ” Retrievers: {', '.join(config.retrievers) if hasattr(config, 'retrievers') else 'Unknown'}", file=sys.stderr)
        
        async with stdio_server() as (read_stream, write_stream):
            await server.run(read_stream, write_stream, server.create_initialization_options())
            
    except Exception as e:
        print(f"âŒ Failed to start MCP server: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())