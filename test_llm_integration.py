#!/usr/bin/env python3
"""
Test the GPT Researcher LLM integration to debug report generation issues
"""
import sys
import os
import asyncio

# Add project root to path
sys.path.insert(0, os.getcwd())

async def test_gpt_researcher_llm():
    print("ğŸ” Testing GPT Researcher LLM integration...")
    
    try:
        # Set environment to use custom retriever
        os.environ['RETRIEVER'] = 'custom'
        os.environ['EGPT_API_KEY'] = 'pak_CG2pyExb0R9eVSbQefJbcuH7nBr8T2KZp1'
        
        from gpt_researcher import GPTResearcher
        print("âœ… GPTResearcher imported")
        
        # Create a researcher instance
        researcher = GPTResearcher(
            query="AI trends 2025",
            report_type="quick_research"
        )
        print("âœ… GPTResearcher initialized")
        
        # Check configuration
        print(f"ğŸ“‹ Configured retriever: {researcher.cfg.retriever}")
        print(f"ğŸ“‹ LLM provider: {researcher.cfg.smart_llm_provider}")
        print(f"ğŸ“‹ LLM model: {researcher.cfg.smart_llm_model}")
        print(f"ğŸ“‹ Temperature: {researcher.cfg.temperature}")
        
        # Test the research process
        print("ğŸ” Conducting research...")
        research_result = await researcher.conduct_research()
        
        # Check research context
        if hasattr(researcher, 'get_research_context'):
            context = researcher.get_research_context()
            context_length = len(context)
            print(f"ğŸ“Š Research context length: {context_length} characters")
            if context_length > 0:
                print(f"ğŸ“„ Context preview: {context[:200]}...")
            else:
                print("âŒ No research context found")
        else:
            print("âš ï¸ No get_research_context method available")
        
        # Test LLM report generation
        print("ğŸ“ Testing report generation...")
        try:
            report = await researcher.write_report()
            if report:
                print(f"âœ… Report generated: {len(report)} characters")
                print(f"ğŸ“„ Report preview: {report[:300]}...")
            else:
                print("âŒ Report generation returned None/empty")
        except Exception as e:
            print(f"âŒ Report generation failed: {e}")
            import traceback
            traceback.print_exc()
            
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_gpt_researcher_llm())